{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/yeboda96/Charlottesville-Albemarle-Connectivity-Survey-Analysis/blob/master/CNN_Car_Classification.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "lEfCYdyhTyQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import shutil\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mMeQy5g_UAdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ab86c54d-9ca8-447b-a754-2e450a435b49"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ll778O7XWLN0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "from keras.applications import vgg19\n",
        "from keras.applications import resnet50\n",
        "from keras.applications import inception_v3\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
        "from keras.models import Model,Sequential\n",
        "from keras import optimizers\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import argparse\n",
        "from time import time\n",
        "\n",
        "from skimage import exposure, color\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('tf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNb0uGI7uHxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_model(train_dir,val_dir,batch_size=16,model_name='vgg16',num_class=2,img_size=224):\n",
        "    \"\"\"\n",
        "    initialize cnn model and training and validation data generator\n",
        "    parms:\n",
        "        args: parsed commandline arguments\n",
        "    return:\n",
        "        model: initialized model\n",
        "        train_generator: training data generator\n",
        "        validation_generator: validation data generator\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    print('loading the model and the pre-trained weights...')\n",
        "\n",
        "    # load base model\n",
        "    if model_name == 'vgg16':\n",
        "        base_model = vgg16.VGG16(include_top=False, weights='imagenet', input_shape = (224,224,3)) # need specify input_shape\n",
        "        # this preprocess_input is the default preprocess func for given network, you can change it or implement your own \n",
        "        # use inception_v3 preprocess for vgg16, it seems that it works better than vgg16.preprocess_input\n",
        "        preprocess_input = inception_v3.preprocess_input \n",
        "\n",
        "    # initalize training image data generator\n",
        "    # you can also specify data augmentation here\n",
        "    train_datagen = image.ImageDataGenerator(\n",
        "        # width_shift_range=0.1,\n",
        "        # height_shift_range=0.1,\n",
        "        # samplewise_center=True,\n",
        "        # samplewise_std_normalization=True,\n",
        "        # rescale=1./255,\n",
        "        preprocessing_function=preprocess_input, # preprocess_input,\n",
        "        # rotation_range=30,\n",
        "        # shear_range=0.1,\n",
        "        # zoom_range=0.1,\n",
        "        # vertical_flip=True,\n",
        "        horizontal_flip=True\n",
        "        )\n",
        "\n",
        "    # initalize validation image data generator\n",
        "    # you can also specify data augmentation here\n",
        "    validation_datagen = image.ImageDataGenerator(\n",
        "        # samplewise_center=True,\n",
        "        # samplewise_std_normalization=True\n",
        "        # rescale=1./255\n",
        "        preprocessing_function=preprocess_input # preprocess_input\n",
        "        )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        # color_mode='grayscale', # 'rgb'\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        # color_mode='grayscale',  # 'rgb'\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    # fix base_model layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # added some customized layers for your own data\n",
        "    x = base_model.output\n",
        "    if model_name == 'vgg16':\n",
        "        x = Flatten(name='flatten')(x)\n",
        "        x = Dense(512, activation='relu', name='fc1-pretrain')(x)\n",
        "        x = Dense(256, activation='relu', name='fc2-pretrain')(x)\n",
        "        x = Dropout(0.5, name='dropout')(x)\n",
        "\n",
        "    # added softmax layer\n",
        "    predictions = Dense(num_class, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "    return model, train_generator, validation_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_r-lCXKuXbB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, train_generator, validation_generator, num_class= 2,model_name='vgg16', batch_size=16, epochs=30, suffix='laioffer'):\n",
        "    \"\"\"\n",
        "    train the model\n",
        "    parms:\n",
        "        model: initialized model\n",
        "        train_generator: training data generator\n",
        "        validation_generator: validation data generator\n",
        "        args: parsed command line arguments\n",
        "    return:\n",
        "    \"\"\"\n",
        "    # define number of steps/iterators per epoch\n",
        "    stepsPerEpoch = train_generator.samples / batch_size\n",
        "    validationSteps= validation_generator.samples / batch_size\n",
        "\n",
        "    # save the snapshot of the model to local drive\n",
        "    pretrain_model_name = 'pretrained_{}_{}_{}_{}.h5'.format(model_name, num_class, epochs, suffix)\n",
        "    # visualize the training process\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/{}_pretrain_{}\".format(model_name, time()), histogram_freq=0, write_graph=True)\n",
        "    checkpoint = ModelCheckpoint(pretrain_model_name, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "    callbacks_list = [checkpoint, tensorboard]\n",
        "\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=stepsPerEpoch,\n",
        "        epochs=epochs,\n",
        "        callbacks = callbacks_list,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps=validationSteps)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cR1uYZGLyP7u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "73j3rbLL30i2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IHr689LR4jok",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth \n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agHNt1Kl4oU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "dfa309c4-e748-4982-ac6d-b891ccb27525"
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "\n",
        "from oauth2client.client import GoogleCredentials \n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_GZUrY8l42N-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "\n",
        "!mkdir -p drive\n",
        "\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WqQ96MYc47tC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "03f06450-b263-4def-ad2d-ccca567d3ff6"
      },
      "cell_type": "code",
      "source": [
        "print ('Files in Drive:')\n",
        "\n",
        "!ls drive/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in Drive:\n",
            " 545_Team5_PP.doc\n",
            " 545_Team5_PP.doc.odt\n",
            " car_devkit.tgz\n",
            " cars_test\n",
            " cars_test_annos_withlabels.mat\n",
            " cars_train\n",
            "'Charlottesville _ Albemarle Connectivity Survey.desktop'\n",
            "'Colab Notebooks'\n",
            "'CREATE TABLE Train.docx'\n",
            " Data_Science_1.03.pdf\n",
            "'How to get started with Drive'\n",
            "'MGMT 382'\n",
            "'MGMT 451 Presentation - Bar chart 1.ods'\n",
            "'MGMT 451 Presentation - Column chart 1.ods'\n",
            "'MGMT 451 Presentation - Column chart 3.ods'\n",
            "'MGMT 451 Presentation - Line chart 1.ods'\n",
            "'MGMT 451 Presentation - Line chart 2.ods'\n",
            "'MGMT 451 Presentation - Line chart 3.ods'\n",
            "'mgmt 472'\n",
            "'MGMT 488.odt'\n",
            " MGMT_488_yelp\n",
            "'Project 1 Plan.docx'\n",
            "'Project 1 Plan.docx.odt'\n",
            " project2\n",
            "'project 2.odt'\n",
            "'project 2.pdf'\n",
            " UCA\n",
            "'Untitled document.odt'\n",
            "'Untitled document.odt (19b934c1)'\n",
            "'Untitled presentation.pdf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Yvky52W4-ty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "39b44e79-833e-4b2a-fa0d-1f91ae58fc66"
      },
      "cell_type": "code",
      "source": [
        "model, train_generator, validation_generator = init_model('drive/cars_train', 'drive/cars_test')\n",
        "train(model, train_generator, validation_generator)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading the model and the pre-trained weights...\n",
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-16a63c325829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/cars_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drive/cars_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-ee502c57b519>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_generator, validation_generator, num_class, model_name, batch_size, epochs, suffix)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         validation_steps=validationSteps)\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2266\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m                 \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ProgbarLogger' object has no attribute 'log_values'"
          ]
        }
      ]
    }
  ]
}